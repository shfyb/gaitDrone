# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import os
import sys

import cv2
import numpy as np
from tqdm import tqdm
from PIL import Image
import torch
# __dir__ = os.path.dirname(os.path.abspath(__file__))
# sys.path.append(os.path.abspath(os.path.join(__dir__, '../../../')))
# from paddleseg.utils import get_sys_env, logger, get_image_list
# from paddleseg.utils import get_sys_env, logger, get_image_list

from mmln_main.train_supervision import Supervision_Train  # 参考测试代码中的模型加载方式
from mmln_main.cfg import py2cfg

def parse_args():
    parser = argparse.ArgumentParser(
        description='PP-HumanSeg inference for video')
    parser.add_argument(
        "--config",
        help="The config file of the inference model.",
        type=str,
        required=True)
    parser.add_argument(
        '--img_path', help='The image that to be predicted.', type=str)
    parser.add_argument(
        '--video_path', help='Video path for inference', type=str)
    parser.add_argument(
        '--bg_img_path',
        help='Background image path for replacing. If not specified, a white background is used',
        type=str)
    parser.add_argument(
        '--bg_video_path', help='Background video path for replacing', type=str)
    parser.add_argument(
        '--save_dir',
        help='The directory for saving the inference results',
        type=str,
        default='./output')

    parser.add_argument(
        '--vertical_screen',
        help='The input image is generated by vertical screen, i.e. height is bigger than width.'
        'For the input image, we assume the width is bigger than the height by default.',
        action='store_true')
    parser.add_argument(
        '--use_post_process', help='Use post process.', action='store_true')
    parser.add_argument(
        '--use_optic_flow', help='Use optical flow.', action='store_true')
    parser.add_argument(
        '--test_speed',
        help='Whether to test inference speed',
        action='store_true')

    return parser.parse_args()


class MMNLPredictor:
    """MMLN 模型推理封装类"""
    def __init__(self, config_path, checkpoint_path):
        # 从测试代码中提取配置加载逻辑
        self.config = py2cfg(config_path)  # 需实现 py2cfg 或替换为实际配置加载方法
        
        self.model = Supervision_Train.load_from_checkpoint(
            checkpoint_path, config=self.config
        )
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        self.model.eval()
    
    def preprocess(self, img):
        """预处理函数（与 LoveDA 测试代码对齐）"""
        # 调整尺寸（假设 MMLN 输入尺寸为 512x512）
        # img = cv2.resize(img, (self.config.input_size, self.config.input_size))

        # 归一化到 [0,1]（根据 MMLN 实际需求调整）
        img = img.astype(np.float32) / 255.0
        # 转换为 PyTorch Tensor 并调整维度顺序
        img = torch.from_numpy(img).permute(2, 0, 1)  # HWC -> CHW
        return img.unsqueeze(0)  # 添加 batch 维度
    
    def postprocess(self, pred_mask, original_shape):
        """后处理函数（生成二值化掩码）"""

        # 将预测结果还原到原始图像尺寸
        pred_mask = cv2.resize(pred_mask, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_NEAREST)

        # 生成二值化掩码（假设类别1为前景）
        out_mask = np.where(pred_mask == 6, 255, 0).astype(np.uint8)

        return out_mask
    
    def run(self, img, bg_img=None):
        original_shape = img.shape[:2]
        input_tensor = self.preprocess(img).to(self.device)
    
        with torch.no_grad():
        # 确保模型返回的是 logits 张量
            output = self.model(input_tensor)
            print("[Debug] Output type:", type(output))  # 检查输出类型
        
        # 处理多返回值情况（如模型返回 loss 或辅助输出）
            if isinstance(output, (tuple, list)):
                output = output[0]  # 假设 logits 是第一个返回值
        
        # 获取预测掩码并转换为 NumPy
            pred_mask = output.argmax(dim=1)  # shape: [1, H, W]
            pred_mask = pred_mask.squeeze(0)   # 移除 batch 维度 -> [H, W]
            pred_mask = pred_mask.cpu().numpy().astype(np.uint8)  # 转换为 uint8
    
    # 验证是否为 NumPy 数组
        assert isinstance(pred_mask, np.ndarray), f"pred_mask is {type(pred_mask)}, expected numpy.ndarray"
        out_mask = self.postprocess(pred_mask, original_shape)
        return img, out_mask
    
def get_bg_img(bg_img_path, img_shape):
    if bg_img_path is None:
        bg = 255 * np.ones(img_shape)
    elif not os.path.exists(bg_img_path):
        raise Exception('The --bg_img_path is not existed: {}'.format(
            bg_img_path))
    else:
        bg = cv2.imread(bg_img_path)
    return bg


def makedirs(save_dir):
    dirname = save_dir if os.path.isdir(save_dir) else \
        os.path.dirname(save_dir)
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def seg_image(img, config, checkpoint,  save_name, savesil_path):

    """修改后的分割函数"""
    # 初始化 MMLN 预测器（需传入配置文件路径和权重路径）
    predictor = MMNLPredictor(
        config_path=config,  # 替换为实际 MMLN 配置文件路径
        checkpoint_path=checkpoint  # 替换为实际权重路径
    )
    
    # 执行推理（不再需要 bg_img，但保留接口兼容）
    _, out_mask = predictor.run(img)
    
    # 保存结果（与原逻辑一致）
    if not os.path.exists(savesil_path):
        os.makedirs(savesil_path)
    savesil_name = os.path.join(savesil_path, save_name)
    cv2.imwrite(savesil_name, out_mask)



def seg_video(args):
    assert os.path.exists(args.video_path), \
        'The --video_path is not existed: {}'.format(args.video_path)
    assert args.save_dir.endswith(".avi"), 'The --save_dir should be xxx.avi'

    cap_img = cv2.VideoCapture(args.video_path)
    assert cap_img.isOpened(), "Fail to open video:{}".format(args.video_path)
    fps = cap_img.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap_img.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap_img.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap_img.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap_out = cv2.VideoWriter(args.save_dir,
                              cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps,
                              (width, height))

    if args.bg_video_path is not None:
        assert os.path.exists(args.bg_video_path), \
            'The --bg_video_path is not existed: {}'.format(args.bg_video_path)
        is_video_bg = True
        cap_bg = cv2.VideoCapture(args.bg_video_path)
        assert cap_bg.isOpened(), "Fail to open video:{}".format(
            args.bg_video_path)
        bg_frame_nums = cap_bg.get(cv2.CAP_PROP_FRAME_COUNT)
        bg_frame_idx = 1
    else:
        is_video_bg = False
        bg = get_bg_img(args.bg_img_path, [height, width, 3])

    # logger.info("Input: video")
    # logger.info("Create predictor...")
    predictor = Predictor(args)

    # logger.info("Start predicting...")
    with tqdm(total=total_frames) as pbar:
        img_frame_idx = 0
        while cap_img.isOpened():
            ret_img, img = cap_img.read()
            if not ret_img:
                break

            if is_video_bg:
                ret_bg, bg = cap_bg.read()
                if not ret_bg:
                    break
                bg_frame_idx += 1
                if bg_frame_idx == bg_frame_nums:
                    bg_frame_idx = 1
                    cap_bg.set(cv2.CAP_PROP_POS_FRAMES, 0)

            out = predictor.run(img, bg)
            cap_out.write(out)
            img_frame_idx += 1
            pbar.update(1)

    cap_img.release()
    cap_out.release()
    if is_video_bg:
        cap_bg.release()


def seg_camera(args):
    cap_camera = cv2.VideoCapture(0)
    assert cap_camera.isOpened(), "Fail to open camera"
    width = int(cap_camera.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap_camera.get(cv2.CAP_PROP_FRAME_HEIGHT))

    if args.bg_video_path is not None:
        assert os.path.exists(args.bg_video_path), \
            'The --bg_video_path is not existed: {}'.format(args.bg_video_path)
        is_video_bg = True
        cap_bg = cv2.VideoCapture(args.bg_video_path)
        bg_frame_nums = cap_bg.get(cv2.CAP_PROP_FRAME_COUNT)
        bg_frame_idx = 1
    else:
        is_video_bg = False
        bg = get_bg_img(args.bg_img_path, [height, width, 3])

    # logger.info("Input: camera")
    # logger.info("Create predictor...")
    predictor = Predictor(args)

    # logger.info("Start predicting...")
    while cap_camera.isOpened():
        ret_img, img = cap_camera.read()
        if not ret_img:
            break

        if is_video_bg:
            ret_bg, bg = cap_bg.read()
            if not ret_bg:
                break
            if bg_frame_idx == bg_frame_nums:
                bg_frame_idx = 1
                cap_bg.set(cv2.CAP_PROP_POS_FRAMES, 0)
            bg_frame_idx += 1

        out = predictor.run(img, bg)
        cv2.imshow('PP-HumanSeg', out)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    if is_video_bg:
        cap_bg.release()
    cap_camera.release()


if __name__ == "__main__":
    args = parse_args()
    # env_info = get_sys_env()
    # args.use_gpu = True if env_info['Paddle compiled with cuda'] \
    #     and env_info['GPUs used'] else False

    makedirs(args.save_dir)

    if args.img_path is not None:
        seg_image(args)
    elif args.video_path is not None:
        seg_video(args)
    else:
        seg_camera(args)
